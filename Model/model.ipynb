{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608eea4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, Lambda, BatchNormalization\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "from keras_vggface import utils\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449421f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "global left\n",
    "global right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeba540",
   "metadata": {},
   "outputs": [],
   "source": [
    "left = '/mnt/data/left_new/left'\n",
    "right = '/mnt/data/right_new/right'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2834ee0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enabling gpu\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices, physical_devices[0])\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89606fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating positive and negative pairs from dataset\n",
    "\n",
    "def random_element_except(arr, exclude):\n",
    "    return random.choice([element for element in arr if element != exclude])\n",
    "\n",
    "def load_celeb_dataset(left, right):\n",
    "    left_images = os.listdir(left)\n",
    "    right_images = os.listdir(right)\n",
    "    counter = 0\n",
    "    labels = []\n",
    "    pairs = []\n",
    "    for ele in right_images:\n",
    "        if ele in left_images:\n",
    "            pairs.append([ele, ele])\n",
    "            labels.append(1)\n",
    "            random_image = random_element_except(left_images, ele)\n",
    "            counter+=1\n",
    "#             print(counter)\n",
    "            pairs.append([ele, random_image])\n",
    "            labels.append(0)\n",
    "    return np.array(pairs), np.array(labels).astype(\"float32\")\n",
    "pairs, labels = load_celeb_dataset(left, right)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d19979",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_val, x_test, y_train_val, y_test = train_test_split(\n",
    "        pairs, labels, test_size=0.2, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ec09f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep 50% of train_val  in validation set\n",
    "n = int(len(x_train_val) /2)\n",
    "\n",
    "x_train, x_val = x_train_val[:n], x_train_val[n:]\n",
    "y_train, y_val = y_train_val[:n], y_train_val[n:]\n",
    "del x_train_val, y_train_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89e1b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape, x_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaee50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame({\"image1\": x_train[:, 0], \"image2\": x_train[:, 1], \"label\": y_train})\n",
    "df_test = pd.DataFrame({\"image1\": x_test[:, 0], \"image2\": x_test[:, 1], \"label\": y_test})\n",
    "df_valid = pd.DataFrame({\"image1\": x_val[:, 0], \"image2\": x_val[:, 1], \"label\": y_val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82278521",
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing pair and label in csv\n",
    "\n",
    "df_train.to_csv(\"../csv/training.csv\", header=True, index=False)\n",
    "df_test.to_csv(\"../csv/testing.csv\", header=True, index=False)\n",
    "df_valid.to_csv(\"../csv/validation.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b25e819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your image dimensions\n",
    "image_width = 224\n",
    "image_height = 224\n",
    "\n",
    "# Set batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "\n",
    "def data_generator(csv_file):\n",
    "    data = pd.read_csv(csv_file)\n",
    "\n",
    "    while True:\n",
    "        # Shuffle the data at the beginning of each epoch\n",
    "        data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "        # Initialize empty arrays for the image pairs and labels\n",
    "        x1 = np.zeros((batch_size, image_width, image_height, 3))\n",
    "        x2 = np.zeros((batch_size, image_width, image_height, 3))\n",
    "        y = np.zeros(batch_size)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            # Get the image paths and label for the current batch index\n",
    "            image1_path = data['image1'].iloc[i]\n",
    "            image2_path = data['image2'].iloc[i]\n",
    "            label = data['label'].iloc[i]\n",
    "\n",
    "            # Load and preprocess the first image\n",
    "            image1 = load_img(right + \"/\" + image1_path, target_size=(image_width, image_height))\n",
    "            image1 = img_to_array(image1)\n",
    "            image1 = utils.preprocess_input(image1, version=1) # or version=2\n",
    "\n",
    "            # Load and preprocess the second image\n",
    "            image2 = load_img(left + \"/\" + image2_path, target_size=(image_width, image_height))\n",
    "            image2 = img_to_array(image2)\n",
    "            image2 = utils.preprocess_input(image2, version=1) # or version=2\n",
    "\n",
    "            # Assign the images and label to the batch arrays\n",
    "            x1[i] = image1\n",
    "            x2[i] = image2\n",
    "            y[i] = label\n",
    "\n",
    "        # Yield the image pairs and labels\n",
    "        yield [x1, x2], y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd771d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = data_generator(\"../csv/training.csv\")\n",
    "test_generator = data_generator(\"../csv/testing.csv\")\n",
    "validation_generator = data_generator(\"../csv/validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138abacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = tf.math.reduce_sum(tf.math.square(x - y), axis=1, keepdims=True)\n",
    "    return tf.math.sqrt(tf.math.maximum(sum_square, tf.keras.backend.epsilon()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e08de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, BatchNormalization, Lambda, Dropout\n",
    "from keras_vggface.vggface import VGGFace\n",
    "\n",
    "# Load the VGGFace model without the top (fully connected) layers\n",
    "base_model = VGGFace(model='vgg16', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the layers in the base model to prevent them from being trained\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add additional layers on top of the VGGFace base model\n",
    "flatten = Flatten()(base_model.output)\n",
    "dense1 = Dense(512, activation=\"relu\")(flatten)\n",
    "dense1 = Dropout(0.3)(dense1)\n",
    "dense1 = BatchNormalization()(dense1)\n",
    "dense2 = Dense(256, activation=\"relu\")(dense1)\n",
    "dense2 = Dropout(0.3)(dense2)\n",
    "dense2 = BatchNormalization()(dense2)\n",
    "output = Dense(256)(dense2)\n",
    "\n",
    "# Create the embedding network with the VGGFace base model and additional layers\n",
    "embedding_network = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "input_1 = Input((224, 224, 3))\n",
    "input_2 = Input((224, 224, 3))\n",
    "\n",
    "# As mentioned above, the Siamese Network shares weights between\n",
    "# tower networks (sister networks). To allow this, we will use\n",
    "# the same embedding network for both tower networks.\n",
    "tower_1 = embedding_network(input_1)\n",
    "tower_2 = embedding_network(input_2)\n",
    "merge_layer = Lambda(euclidean_distance)([tower_1, tower_2])\n",
    "normal_layer = BatchNormalization()(merge_layer)\n",
    "normal_layer = Dropout(0.3)(normal_layer)\n",
    "output_layer = Dense(1, activation=\"sigmoid\")(normal_layer)\n",
    "siamese = Model(inputs=[input_1, input_2], outputs=output_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296dab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(margin=1):\n",
    "    def contrastive_loss(y_true, y_pred):\n",
    "        square_pred = tf.math.square(y_pred)\n",
    "        margin_square = tf.math.square(tf.math.maximum(margin - (y_pred), 0))\n",
    "        return tf.math.reduce_mean(\n",
    "            (1 - y_true) * square_pred + (y_true) * margin_square\n",
    "        )\n",
    "\n",
    "    return contrastive_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c884b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(learning_rate=1e-4)\n",
    "\n",
    "siamese.compile(loss=loss(margin=1), optimizer=adam, metrics=[\"accuracy\"])\n",
    "siamese.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5494fe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"/../csv/training.csv\")\n",
    "df_test = pd.read_csv(\"../csv/testing.csv\")\n",
    "df_validation = pd.read_csv(\"../csv/validation.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce281d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.backend.clear_session()\n",
    "# tf.random.set_seed(101)\n",
    "# np.random.seed(101)\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', patience=10)\n",
    "ck = ModelCheckpoint(\"../Backend/models/model.h5\", monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "\n",
    "history = siamese.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(df_train) // batch_size,\n",
    "    epochs=100,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(df_validation) // batch_size,\n",
    "    callbacks=[es, ck]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
